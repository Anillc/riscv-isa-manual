== "D" 扩展用于双精度浮点数，版本 2.2

本章介绍了标准双精度浮点指令集扩展，名为 "D"，它增加了符合 IEEE 754-2008 算术标准的双精度浮点计算指令。 D 扩展依赖于基础的单精度指令子集 F。
(((双精度, 浮点)))
(((浮点, 双精度)))

=== D 寄存器状态

D 扩展将 32 个浮点寄存器 `f0-f31` 扩展到 64 位（在 <<fprs>> 中 FLEN=64）。 `f` 寄存器现在可以容纳 32 位或 64 位浮点值，具体描述如下 <<nanboxing>>。

[NOTE]
====
FLEN 可以是 32、64 或 128，这取决于支持的 F、D 和 Q 扩展。 最多可以支持四种不同的浮点精度，包括 H、F、D 和 Q。
====

(((浮点, 支持的精度)))

[[nanboxing]]
=== 窄值的 NaN 包装

当支持多种浮点精度时，较窄的 _n_-bit 类型的有效值，_n_<FLEN，通过 FLEN-bit NaN 值的低 _n_ 位表示，在这个过程中称为 NaN 包装。 有效的 NaN 包装值的高位必须全为 1。 因此，合法的 NaN 包装 _n_-bit 值在被视为任何更宽的 _m_-bit 值时表现为负静默 NaN（qNaN），_n_ < _m_ &#8804; FLEN。 任何将较窄结果写入 'f' 寄存器的操作都必须在上层 FLEN-_n_ 位写入全 1，以生成合法的 NaN 包装值。
(((浮点, 要求)))

[NOTE]
====
软件可能不知道浮点寄存器中存储的数据的当前类型，但必须能够保存和恢复寄存器值，因此必须定义使用更广泛操作传输较窄值的结果。 一种常见情况是针对被调用者保存的寄存器，但也需要一种标准约定来支持包括可变参数、用户级线程库、虚拟机迁移和调试在内的功能。
====

浮点 _n_-bit 传输操作将IEEE 标准格式的外部值移入和移出 `f` 寄存器，并包括浮点加载和存储 (FL__n__/FS__n__) 以及浮点移动指令 (FMV._n_.X/FMV.X._n_)。 较窄的 _n_-bit 传输，_n_<FLEN，进入 `f` 寄存器会创建一个有效的 NaN 包装值。 从浮点寄存器出来的较窄 _n_-bit 传输将传输寄存器的低 _n_ 位而忽略上层 FLEN-_n_ 位。

除了上一段描述的传输操作外，所有其他针对较窄 __n__-bit 操作，_n_<FLEN 的浮点操作都检查输入操作数是否正确地 NaN 包装，即所有上层 FLEN-_n_ 位为 1。 如果是，则使用输入的 _n_ 个最低有效位作为输入值，否则将输入值视为 _n_ 位规范 NaN。

[TIP]
====
本文件的早期版本没有定义将较窄或较宽操作数的结果引入操作的行为，除了要求较宽的保存和恢复将保留较窄操作数的值。 新的定义消除了这种特定于实现的行为，同时仍然适应浮点单元的非重编码和重编码实现。 新的定义还通过在使用值不正确时传播 NaN，帮助捕捉软件错误。

非重编码实现会在每次浮点操作的输入和输出时将操作数解包并重新打包为 IEEE 标准格式。 对于非重编码实现，NaN 包装的成本主要在于检查较窄运算的上层位是否代表一个合法的 NaN 包装值，以及在结果的上层位写入全 1。

重编码实现使用更便捷的内部格式表示浮点值，增加了一个指数位以允许所有值保持标准化。 重编码实现的成本主要在于跟踪内部类型和符号位所需的额外标记，但这可以通过在指数字段内部重新编码 NaN 来完成而不增加新的状态位。 对用于在重编码格式中传输值的管道进行小修改，但数据路径和延迟成本是最小的。 重编码过程必须处理宽操作数输入亚正规值的移位，提取 NaN 包装值的过程与标准化类似，只是跳过前导 1 位而不是跳过前导 0 位，允许数据路径复用共享。
====

[[fld_fsd]]
=== 双精度负载和存储指令

FLD 指令从存储器中加载双精度浮点值到浮点寄存器 _rd_。 FSD 从浮点寄存器存储双精度值到存储器中。
(((浮点, 加载和存储)))

[NOTE]
====
双精度值可以是 NaN 包装的单精度值。
====

include::images/wavedrom/double-ls.adoc[]

//.Double-precision load and store

FLD 和 FSD 仅在有效地址自然对齐且 XLEN&#8805;64 时保证原子执行。

FLD 和 FSD 不会修改正在传输的位；特别是，非规范 NaN 的有效载荷会被保留。

=== 双精度浮点计算指令

双精度浮点计算指令与其单精度对应物相似，但对双精度操作数进行操作并生成双精度结果。

include::images/wavedrom/double-fl-compute.adoc[]

//.Double-precision float computational

=== 双精度浮点转换和移动指令

浮点到整数和整数到浮点转换指令在 OP-FP 主操作码空间中编码。 FCVT.W.D 或 FCVT.L.D 将浮点寄存器 _rs1_ 中的双精度浮点数转换为有符号的 32 位或 64 位整数，分别在整数寄存器 _rd_ 中。 FCVT.D.W 或 FCVT.D.L 将一个 32 位或 64 位有符号整数，分别在整数寄存器 _rs1_ 中，转换为浮点寄存器 _rd_ 中的双精度浮点数。 FCVT.WU.D、FCVT.LU.D、FCVT.D.WU 和 FCVT.D.LU 变体从或转换为无符号整数值。 对于 RV64，FCVT.W[U].D 进行符号扩展以生成 32 位结果。 FCVT.L[U].D 和 FCVT.D.L[U] 是 RV64 专用指令。
FCVT._int_.D 的有效输入范围及无效输入的行为与 FCVT._int_.S 相同。
(((浮点, 转换和移动)))

所有浮点到整数和整数到浮点的转换指令根据 _rm_ 字段进行舍入。 注意 FCVT.D.W[U] 总是产生精确结果，且不受舍入模式影响。

include::images/wavedrom/double-fl-convert-mv.adoc[]

//.Double-precision float convert and move

从双精度到单精度和从单精度到
双精度的转换指令，FCVT.S.D 和 FCVT.D.S，在 OP-FP 主操作码空间中编码，源和目标都是浮点寄存器。 _rs2_ 字段编码源的数据类型，而 _fmt_ 字段编码目标的数据类型。 FCVT.S.D 根据 RM 字段进行舍入；FCVT.D.S 永远不进行舍入。
(((双精度, 单精度)))
(((单精度, 双精度)))

include::images/wavedrom/fcvt-sd-ds.adoc[]

//.Double-precision FCVT.S.D and FCVT.D.S

浮点到浮点符号注入指令 FSGNJ.D、FSGNJN.D 和 FSGNJX.D 定义类似于单精度符号注入指令。

//FSGNJ.D, FSGNJN.D, and FSGNJX.D

include::images/wavedrom/fsjgnjnx-d.adoc[]

//.Double-precision sign-injection

仅对 XLEN&#8805;64 提供指令，以便在浮点寄存器和整数寄存器之间移动位模式。 FMV.X.D 将浮点寄存器 _rs1_ 中的双精度值移动到整数寄存器 _rd_ 中，以 IEEE 754-2008 标准编码表示。 FMV.D.X 将整数寄存器 _rs1_ 中以 IEEE 754-2008 标准编码表示的双精度值移动到浮点寄存器 _rd_。

FMV.X.D 和 FMV.D.X 不修改正在传输的位；特别是，非规范 NaN 的有效载荷会被保留。

include::images/wavedrom/d-xwwx.adoc[]

//.Double-precision float move to _rd_

[TIP]
====
RISC-V ISA 的早期版本提供了额外的指令，允许 RV32 系统在 64 位浮点寄存器的上下部分与整数寄存器之间进行传输。 然而，这将是唯一具有部分寄存器写入的指令，并且在重编码浮点或寄存器重命名的实现中会增加复杂性，需要执行管道读-修改-写序列。
若要遵循此模式，扩展到处理 RV32 和 RV64 的四重精度也需要额外的指令。 ISA 被定义为减少显式整数-浮点寄存器移动的数量，通过使转换和比较将结果写入到适当的寄存器文件中，因此我们预计这些指令的收益低于其他 ISA。

我们注意到，对于实现 64 位浮点单元的系统，包括融合乘加支持和 64 位浮点加载和存储，从 32 位整数数据路径扩展到 64 位的边际硬件成本很低，而软件 ABI 支持 32 位宽地址空间和指针可以用于避免静态数据和动态内存流量的增长。
====

=== 双精度浮点比较指令

双精度浮点比较指令的定义类似于其单精度对应物，但对双精度操作数进行操作。
(((浮点, 比较)))

include::images/wavedrom/double-fl-compare.adoc[]

//.Double-precision float compare

=== 双精度浮点分类指令

双精度浮点分类指令 FCLASS.D 的定义类似于其单精度对应物，但操作于双精度操作数。
(((浮点, 分类)))

include::images/wavedrom/double-fl-class.adoc[]

//.Double-precision float classify